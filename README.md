# WeaveWave: Towards Multimodal Music Generation
# WeaveWave: æ¢ç´¢å¤šæ¨¡æ€éŸ³ä¹ç”Ÿæˆ

<div align="center">
   <img src="assets/logo/WeaveWave.png" alt="WeaveWave Logo" width="500px">
</div>
<p align="center">
   <i>WeaveWave: Towards Multimodal Music Generation</i>
</p>

<div align="center">
  
[English](#overview) | [ä¸­æ–‡](#æ¦‚è¿°)
  
![Python Version](https://img.shields.io/badge/python-3.9%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.1.0-red)
![Status](https://img.shields.io/badge/status-in%20progress-yellow)
![License](https://img.shields.io/badge/license-MIT-green)

</div>

## Overview

Artificial Intelligence Generated Content (AIGC), as a next-generation content production method, is reshaping the possibilities in artistic creation. This project focuses on the vertical domain of music generation, exploring advanced models for music generation under multimodal conditions (text, images, videos).

**For humans**, music creation can be abstracted into two stages: **inspiration** and **implementation**. The former originates from the **fusion of diverse sensory experiences**: visual scenes stimulation, literary imagery resonance, auditory fragment association, and other cross-modal perceptions. The latter manifests as the process of concretizing inspiration through singing, instrumental performance, etc.

**For machines**, can artificial intelligence music creation mimic these two stages? We believe that the task of **multimodal music generation** precisely simulates "inspiration" and "implementation," where "inspiration" can be viewed as multimodal data, and "implementation" as a music generation model.

<div align="center">
   <img src="assets/media/inspiration.png" alt="Music Creation: Humans and Machines" width="500px">
</div>
<p align="center">
   <i>Music creation: humans and machines</i>
</p>

However, research on multimodal music generation has not yet garnered widespread attention, with most existing work confined to music understanding and generation within a single modality. This limitation clearly fails to fully capture the complex multimodal sources of inspiration in music creation.

To address this gap, we have adopted a **text-bridging** strategy, leveraging the potential of existing multimodal large language models and text-to-music generation models. This approach has led to the development of WeaveWave, a comprehensive music generation framework that integrates multimodal inputs.

<div align="center">
   <img src="assets/media/frame-1.png" alt="WeaveWaveï¼šæ–‡æœ¬æ¡¥æ¥" width="500px">
</div>
<p align="center">
   <i>WeaveWaveï¼šæ–‡æœ¬æ¡¥æ¥</i>
</p>

## Features

- **Text-and-Style-to-Music Generation**: Generate music based on both textual descriptions and style references
- **Built on Facebook's MusicGen-Style**: Leverages state-of-the-art architecture from AudioCraft
- **Multimodal Input Support**: Process and combine information from various modalities
- **Customizable Training Pipeline**: Flexible configuration for different training scenarios
- **Comprehensive Evaluation Tools**: Assess music generation quality across different input conditions

## Project Status

âš ï¸ **Work in Progress**: This project is currently under active development.

- âœ… Framework design and architecture
- âœ… Basic training pipeline implementation
- âœ… Evaluation metrics design
- ğŸ”„ Dataset preparation and curation (in progress)
- ğŸ”„ Model training and fine-tuning (in progress)
- ğŸ”„ Multimodal integration and testing (in progress)

## Installation

### Requirements

- Python 3.9+
- PyTorch 2.1.0
- CUDA-compatible GPU with at least 8GB memory (16GB+ recommended)

### Setup

1. Clone this repository and the AudioCraft submodule:

```bash
git clone https://github.com/yourusername/WeaveWave.git
cd WeaveWave
git clone https://github.com/facebookresearch/audiocraft.git
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Install AudioCraft:

```bash
cd audiocraft
pip install -e .
cd ..
```

## Dataset

We are currently preparing a comprehensive multimodal music dataset for training. For now, the project includes a dummy dataset generator for testing purposes.

To generate a dummy dataset:

```bash
python prepare_dataset.py --create_dummy --dummy_samples 100
```

## Training

WeaveWave uses Facebook's AudioCraft framework for training, focusing on the MusicGen-Style model architecture.

### Quick Start

```bash
# Generate dummy dataset and start training
python run_training.py --dummy_data --dummy_samples 100
```

### Advanced Configuration

To train with custom settings:

```bash
# Using a specific GPU
python run_training.py --gpu 0 --source_data /path/to/your/data

# View all options
python run_training.py --help
```

## Evaluation

To evaluate a trained model:

```bash
# Basic text-to-music evaluation
python evaluate.py --eval_text2music --model_path ./outputs/latest_model

# Style-to-music evaluation
python evaluate.py --eval_style2music --audio_dir ./eval_samples/styles

# Combined text-and-style-to-music evaluation
python evaluate.py --eval_style_and_text2music --text_file ./eval_samples/prompts.txt --audio_dir ./eval_samples/styles
```

## Demo

<div align="center">
   <a href="assets/media/demo.mp4">
      <img src="assets/media/demo.png" alt="Demo" width="500px">
   </a>
</div>
<p align="center">
  <i>WeaveWave: Web app built with Gradio</i>
</p>

## Project Structure

```
WeaveWave/
â”œâ”€â”€ assets/               # Images, logos, and media files
â”œâ”€â”€ audiocraft/           # Facebook's AudioCraft submodule
â”œâ”€â”€ config/               # Configuration files
â”‚   â”œâ”€â”€ model/            # Model configurations
â”‚   â””â”€â”€ musicgen_style_32khz.yaml  # Main training configuration
â”œâ”€â”€ data/                 # Dataset directory
â”œâ”€â”€ outputs/              # Training outputs and checkpoints
â”œâ”€â”€ evaluate.py           # Evaluation script
â”œâ”€â”€ prepare_dataset.py    # Dataset preparation utilities
â”œâ”€â”€ run_training.py       # Training launcher script
â”œâ”€â”€ train.py              # Main training script
â””â”€â”€ requirements.txt      # Python dependencies
```

## Citation

```
@misc{weavewave2024,
  author = {WeaveWave Team},
  title = {WeaveWave: Towards Multimodal Music Generation},
  year = {2024},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/yourusername/WeaveWave}}
}
```

## Acknowledgements

- This project builds upon [Facebook's AudioCraft](https://github.com/facebookresearch/audiocraft)
- Inspired by [MusicGen](https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md) and [MusicGen-Style](https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN_STYLE.md)

## License

This project is licensed under the MIT License - see the LICENSE file for details.

---

# æ¦‚è¿°

äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰ä½œä¸ºæ–°ä¸€ä»£å†…å®¹ç”Ÿäº§æ–¹å¼ï¼Œæ­£åœ¨é‡å¡‘è‰ºæœ¯åˆ›ä½œé¢†åŸŸçš„å¯èƒ½æ€§ã€‚æœ¬é¡¹ç›®ä¸“æ³¨äºéŸ³ä¹ç”Ÿæˆçš„å‚ç›´é¢†åŸŸï¼Œæ¢ç´¢åœ¨å¤šæ¨¡æ€æ¡ä»¶ï¼ˆæ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ï¼‰ä¸‹çš„éŸ³ä¹ç”Ÿæˆæ¨¡å‹ã€‚

**å¯¹äºäººç±»**ï¼ŒéŸ³ä¹åˆ›ä½œå¯ä»¥æŠ½è±¡ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š**çµæ„Ÿ**å’Œ**å®ç°**ã€‚å‰è€…æºäº**å¤šç§æ„Ÿå®˜ä½“éªŒçš„èåˆ**ï¼šè§†è§‰åœºæ™¯çš„åˆºæ¿€ã€æ–‡å­¦æ„è±¡çš„å…±é¸£ã€å¬è§‰ç‰‡æ®µçš„è”æƒ³ä»¥åŠå…¶ä»–è·¨æ¨¡æ€æ„ŸçŸ¥ã€‚åè€…è¡¨ç°ä¸ºé€šè¿‡æ¼”å”±ã€ä¹å™¨æ¼”å¥ç­‰æ–¹å¼å°†çµæ„Ÿå…·ä½“åŒ–çš„è¿‡ç¨‹ã€‚

**å¯¹äºæœºå™¨**ï¼Œäººå·¥æ™ºèƒ½éŸ³ä¹åˆ›ä½œèƒ½å¦æ¨¡ä»¿è¿™ä¸¤ä¸ªé˜¶æ®µï¼Ÿæˆ‘ä»¬è®¤ä¸ºï¼Œ**å¤šæ¨¡æ€éŸ³ä¹ç”Ÿæˆ**ä»»åŠ¡æ­£æ˜¯å¯¹"çµæ„Ÿ"å’Œ"å®ç°"çš„æ¨¡æ‹Ÿï¼Œå…¶ä¸­"çµæ„Ÿ"å¯ä»¥è§†ä¸ºå¤šæ¨¡æ€æ•°æ®ï¼Œè€Œ"å®ç°"åˆ™æ˜¯éŸ³ä¹ç”Ÿæˆæ¨¡å‹ã€‚

<div align="center">
   <img src="assets/media/inspiration.png" alt="éŸ³ä¹åˆ›ä½œï¼šäººç±»ä¸æœºå™¨" width="500px">
</div>
<p align="center">
   <i>éŸ³ä¹åˆ›ä½œï¼šäººç±»ä¸æœºå™¨</i>
</p>

ç„¶è€Œï¼Œå¤šæ¨¡æ€éŸ³ä¹ç”Ÿæˆçš„ç ”ç©¶å°šæœªå¼•èµ·å¹¿æ³›å…³æ³¨ï¼Œç°æœ‰å¤§éƒ¨åˆ†å·¥ä½œå±€é™äºå•ä¸€æ¨¡æ€å†…çš„éŸ³ä¹ç†è§£å’Œç”Ÿæˆã€‚è¿™ä¸€å±€é™æ€§æ˜¾ç„¶æ— æ³•å……åˆ†æ•æ‰éŸ³ä¹åˆ›ä½œä¸­å¤æ‚çš„å¤šæ¨¡æ€çµæ„Ÿæ¥æºã€‚

ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†**æ–‡æœ¬æ¡¥æ¥**ç­–ç•¥ï¼Œåˆ©ç”¨ç°æœ‰å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å’Œæ–‡æœ¬åˆ°éŸ³ä¹ç”Ÿæˆæ¨¡å‹çš„æ½œåŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¿ƒæˆäº†WeaveWaveçš„å¼€å‘ï¼Œè¿™æ˜¯ä¸€ä¸ªé›†æˆå¤šæ¨¡æ€è¾“å…¥çš„ç»¼åˆéŸ³ä¹ç”Ÿæˆæ¡†æ¶ã€‚

<div align="center">
   <img src="assets/media/frame-1.png" alt="WeaveWaveï¼šæ–‡æœ¬æ¡¥æ¥" width="500px">
</div>
<p align="center">
   <i>WeaveWaveï¼šæ–‡æœ¬æ¡¥æ¥</i>
</p>

## åŠŸèƒ½ç‰¹ç‚¹

- **æ–‡æœ¬ä¸é£æ ¼åˆ°éŸ³ä¹ç”Ÿæˆ**ï¼šåŸºäºæ–‡æœ¬æè¿°å’Œé£æ ¼å‚è€ƒåŒæ—¶ç”ŸæˆéŸ³ä¹
- **åŸºäºFacebookçš„MusicGen-Style**ï¼šåˆ©ç”¨AudioCraftçš„æœ€å…ˆè¿›æ¶æ„
- **å¤šæ¨¡æ€è¾“å…¥æ”¯æŒ**ï¼šå¤„ç†å¹¶ç»“åˆæ¥è‡ªå„ç§æ¨¡æ€çš„ä¿¡æ¯
- **å¯å®šåˆ¶çš„è®­ç»ƒæµç¨‹**ï¼šé’ˆå¯¹ä¸åŒè®­ç»ƒåœºæ™¯çš„çµæ´»é…ç½®
- **å…¨é¢çš„è¯„ä¼°å·¥å…·**ï¼šè¯„ä¼°ä¸åŒè¾“å…¥æ¡ä»¶ä¸‹çš„éŸ³ä¹ç”Ÿæˆè´¨é‡

## é¡¹ç›®çŠ¶æ€

âš ï¸ **æ­£åœ¨è¿›è¡Œä¸­**ï¼šæœ¬é¡¹ç›®ç›®å‰æ­£åœ¨ç§¯æå¼€å‘ä¸­ã€‚

- âœ… æ¡†æ¶è®¾è®¡å’Œæ¶æ„
- âœ… åŸºæœ¬è®­ç»ƒæµç¨‹å®ç°
- âœ… è¯„ä¼°æŒ‡æ ‡è®¾è®¡
- ğŸ”„ æ•°æ®é›†å‡†å¤‡å’Œæ•´ç†ï¼ˆè¿›è¡Œä¸­ï¼‰
- ğŸ”„ æ¨¡å‹è®­ç»ƒå’Œå¾®è°ƒï¼ˆè¿›è¡Œä¸­ï¼‰
- ğŸ”„ å¤šæ¨¡æ€æ•´åˆå’Œæµ‹è¯•ï¼ˆè¿›è¡Œä¸­ï¼‰

## å®‰è£…

### è¦æ±‚

- Python 3.9+
- PyTorch 2.1.0
- å…¼å®¹CUDAçš„GPUï¼Œè‡³å°‘8GBå†…å­˜ï¼ˆæ¨è16GB+ï¼‰

### è®¾ç½®

1. å…‹éš†æ­¤ä»“åº“å’ŒAudioCraftå­æ¨¡å—ï¼š

```bash
git clone https://github.com/yourusername/WeaveWave.git
cd WeaveWave
git clone https://github.com/facebookresearch/audiocraft.git
```

2. å®‰è£…ä¾èµ–ï¼š

```bash
pip install -r requirements.txt
```

3. å®‰è£…AudioCraftï¼š

```bash
cd audiocraft
pip install -e .
cd ..
```

## æ•°æ®é›†

æˆ‘ä»¬ç›®å‰æ­£åœ¨å‡†å¤‡ä¸€ä¸ªå…¨é¢çš„å¤šæ¨¡æ€éŸ³ä¹æ•°æ®é›†ç”¨äºè®­ç»ƒã€‚ç›®å‰ï¼Œé¡¹ç›®åŒ…å«ä¸€ä¸ªç”¨äºæµ‹è¯•çš„è™šæ‹Ÿæ•°æ®é›†ç”Ÿæˆå™¨ã€‚

ç”Ÿæˆè™šæ‹Ÿæ•°æ®é›†ï¼š

```bash
python prepare_dataset.py --create_dummy --dummy_samples 100
```

## è®­ç»ƒ

WeaveWaveä½¿ç”¨Facebookçš„AudioCraftæ¡†æ¶è¿›è¡Œè®­ç»ƒï¼Œä¸“æ³¨äºMusicGen-Styleæ¨¡å‹æ¶æ„ã€‚

### å¿«é€Ÿå¼€å§‹

```bash
# ç”Ÿæˆè™šæ‹Ÿæ•°æ®é›†å¹¶å¼€å§‹è®­ç»ƒ
python run_training.py --dummy_data --dummy_samples 100
```

### é«˜çº§é…ç½®

ä½¿ç”¨è‡ªå®šä¹‰è®¾ç½®è¿›è¡Œè®­ç»ƒï¼š

```bash
# ä½¿ç”¨ç‰¹å®šGPU
python run_training.py --gpu 0 --source_data /path/to/your/data

# æŸ¥çœ‹æ‰€æœ‰é€‰é¡¹
python run_training.py --help
```

## è¯„ä¼°

è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼š

```bash
# åŸºæœ¬æ–‡æœ¬åˆ°éŸ³ä¹è¯„ä¼°
python evaluate.py --eval_text2music --model_path ./outputs/latest_model

# é£æ ¼åˆ°éŸ³ä¹è¯„ä¼°
python evaluate.py --eval_style2music --audio_dir ./eval_samples/styles

# ç»¼åˆæ–‡æœ¬å’Œé£æ ¼åˆ°éŸ³ä¹è¯„ä¼°
python evaluate.py --eval_style_and_text2music --text_file ./eval_samples/prompts.txt --audio_dir ./eval_samples/styles
```

## æ¼”ç¤º

<div align="center">
   <a href="assets/media/demo.mp4">
      <img src="assets/media/demo.png" alt="æ¼”ç¤º" width="500px">
   </a>
</div>
<p align="center">
  <i>WeaveWave: åŸºäºGradioæ„å»ºçš„Webåº”ç”¨</i>
</p>

## é¡¹ç›®ç»“æ„

```
WeaveWave/
â”œâ”€â”€ assets/               # å›¾åƒã€æ ‡å¿—å’Œåª’ä½“æ–‡ä»¶
â”œâ”€â”€ audiocraft/           # Facebookçš„AudioCraftå­æ¨¡å—
â”œâ”€â”€ config/               # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ model/            # æ¨¡å‹é…ç½®
â”‚   â””â”€â”€ musicgen_style_32khz.yaml  # ä¸»è¦è®­ç»ƒé…ç½®
â”œâ”€â”€ data/                 # æ•°æ®é›†ç›®å½•
â”œâ”€â”€ outputs/              # è®­ç»ƒè¾“å‡ºå’Œæ£€æŸ¥ç‚¹
â”œâ”€â”€ evaluate.py           # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ prepare_dataset.py    # æ•°æ®é›†å‡†å¤‡å·¥å…·
â”œâ”€â”€ run_training.py       # è®­ç»ƒå¯åŠ¨è„šæœ¬
â”œâ”€â”€ train.py              # ä¸»è¦è®­ç»ƒè„šæœ¬
â””â”€â”€ requirements.txt      # Pythonä¾èµ–é¡¹
```

## å¼•ç”¨

```
@misc{weavewave2024,
  author = {WeaveWave Team},
  title = {WeaveWave: Towards Multimodal Music Generation},
  year = {2024},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/yourusername/WeaveWave}}
}
```

## è‡´è°¢

- æœ¬é¡¹ç›®åŸºäº[Facebookçš„AudioCraft](https://github.com/facebookresearch/audiocraft)æ„å»º
- å—[MusicGen](https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md)å’Œ[MusicGen-Style](https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN_STYLE.md)çš„å¯å‘

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§LICENSEæ–‡ä»¶ã€‚
